#  second <- sample(c(0,1),1)
}
alice
for(i in 1:100){
count <- 1
won <- 0
first <- sample(c(0,1),1)
second <- sample(c(0,1),1)
while(!won){
if (first&!second){
alice[i] <- count
won <- 1
}
if (first&second){
bob[i] <- count
won <- 1
}
count <- count+1
first <- second
second <- sample(c(0,1),1)
}
#  alice[i] <- first&(!second)
#  bob[i] <- first&second
#  first <- second
#  second <- sample(c(0,1),1)
}
bob
alice
first <- sample(c(0,1),1)
second <- sample(c(0,1),1)
for(i in 1:100){
count <- 1
won <- 0
first <- sample(c(0,1),1)
second <- sample(c(0,1),1)
while(!won){
if (first&!second){
alice[i] <- count
won <- 1
}
count <- count+1
first <- second
second <- sample(c(0,1),1)
}
count <- 1
won <- 0
while(!won){
if (first&second){
bob[i] <- count
won <- 1
}
count <- count+1
first <- second
second <- sample(c(0,1),1)
}
}
bob
alice
hist(alice)
hist(bob)
mean(alice)
sd(alice)
mean(bob)
sd(bob)
alice <- rep(NA,10000)
bob <- rep(NA,10000)
first <- sample(c(0,1),1)
second <- sample(c(0,1),1)
for(i in 1:10000){
count <- 1
won <- 0
first <- sample(c(0,1),1)
second <- sample(c(0,1),1)
while(!won){
if (first&!second){
alice[i] <- count
won <- 1
}
count <- count+1
first <- second
second <- sample(c(0,1),1)
}
count <- 1
won <- 0
while(!won){
if (first&second){
bob[i] <- count
won <- 1
}
count <- count+1
first <- second
second <- sample(c(0,1),1)
}
}
hist(alice)
N <- 10000
alice <- rep(NA,N)
bob <- rep(NA,N)
first <- sample(c(0,1),1)
second <- sample(c(0,1),1)
for(i in 1:N){
count <- 1
won <- 0
first <- sample(c(0,1),1)
second <- sample(c(0,1),1)
while(!won){
if (first&!second){
alice[i] <- count
won <- 1
}
count <- count+1
first <- second
second <- sample(c(0,1),1)
}
count <- 1
won <- 0
while(!won){
if (first&second){
bob[i] <- count
won <- 1
}
count <- count+1
first <- second
second <- sample(c(0,1),1)
}
}
N <- 100000
alice <- rep(NA,N)
bob <- rep(NA,N)
first <- sample(c(0,1),1)
second <- sample(c(0,1),1)
for(i in 1:N){
count <- 1
won <- 0
first <- sample(c(0,1),1)
second <- sample(c(0,1),1)
while(!won){
if (first&!second){
alice[i] <- count
won <- 1
}
count <- count+1
first <- second
second <- sample(c(0,1),1)
}
count <- 1
won <- 0
while(!won){
if (first&second){
bob[i] <- count
won <- 1
}
count <- count+1
first <- second
second <- sample(c(0,1),1)
}
}
hist(alice)
hist(bob,add=TRUE)
par(mfrow(c(1,2)))
par(mfrow=c(1,2))
hist(alice)
hist(bob)
par(mfrow=c(2,1))
hist(alice)
par(mfrow=c(2,1))
hist(alice)
hist(bob)
hist(alice)
hist(alice)
q()
1327+832
606+377
588+395
542+441
874+109
495+488
q()
q()
.3*.9
.3*.9+.09
q()
11.95*.8
q()
5905.70-4696.55
(5905.70-4696.55)/5905.70
q()
Sys.info()
install.packages("rstan", dependencies = TRUE)
source("http://bioconductor.org/biocLite.R")
biocLite("Rgraphviz", type = "source")
q()
install.packages("rstan", dependencies = TRUE)
source("http://bioconductor.org/biocLite.R")
biocLite("Rgraphviz", type = "source")
biocLite("nem")
library(rstan)
rstan_options(auto_write = TRUE)
options(mc.cores = parallel::detectCores())
# Create the stan model object using Stan's syntax
stanmodelcode = "
data { // Data block
int<lower=1> N; // Sample size
int<lower=1> K; // Dimension of model matrix
matrix[N, K] X; // Model Matrix
vector[N] y; // Target variable
}
/*
transformed data { // Transformed data block. Not used presently.
}
*/
parameters { // Parameters block
vector[K] beta; // Coefficient vector
real<lower=0> sigma; // Error scale
}
model { // Model block
vector[N] mu;
mu <- X * beta; // Creation of linear predictor
// priors
beta ~ normal(0, 10);
sigma ~ cauchy(0, 5); // With sigma bounded at 0, this is half-cauchy
// likelihood
y ~ normal(mu, sigma);
}
/*
generated quantities { // Generated quantities block. Not used presently.
}
*/
"
library(rstan)
### Run the model and examine results ###
fit = stan(model_code=stanmodelcode, data=dat, iter=12000,
warmup=2000, thin=10, chains=3)
dat = list(N=N, K=ncol(X), y=y, X=X)
# Chunk 1: defobs
drive = c('texting','texting','texting','not','not',
'texting','texting','not','not','texting')
# convert to numeric, arbitrarily picking texting=1, not=0
driveNum = ifelse(drive=='texting', 1, 0)
N = length(drive) # sample size
nTexting = sum(drive=='texting') # number of drivers texting
nNot = sum(drive=='not') # number of those not
# Chunk 2: histplot
x1 = rbinom(1000, size=10, p=.5)
x2 = rbinom(1000, size=10, p=.85)
par(mfrow=c(1,2))
mean(x1); hist(x1)
mean(x2); hist(x2)
# Chunk 3: thetapar
theta = seq(from=1/(N+1), to=N/(N+1), length=10)
# Chunk 4: chooseprior
### prior distribution
# uniform
# pTheta = dunif(theta)
# beta prior with mean = .5
# pTheta = dbeta(theta, 10, 10)
# triangular as in Kruschke
pTheta = pmin(theta, 1-theta)
pTheta = pTheta/sum(pTheta) # Normalize so sum to 1
# Chunk 5: evaLike
pDataGivenTheta = choose(N, nTexting) * theta^nTexting * (1-theta)^nNot
# Chunk 6: getPosterior
# first we calculate the denominator from Bayes theorem; this is the marginal
# probability of y
pData = sum(pDataGivenTheta*pTheta)
pThetaGivenData = pDataGivenTheta*pTheta / pData # Bayes theorem
# Chunk 7: distData
round(data.frame(theta, prior=pTheta, likelihood=pDataGivenTheta,
posterior=pThetaGivenData), 3)
posteriorMean = sum(pThetaGivenData*theta)
posteriorMean
# Chunk 8: setup
# set seed for replicability
set.seed(8675309)
# create a N x k matrix of covariates
N = 250
K = 3
covariates = replicate(K, rnorm(n=N))
colnames(covariates) = c('X1', 'X2', 'X3')
# create the model matrix with intercept
X = cbind(Intercept=1, covariates)
# create a normally distributed variable that is a function of the covariates
coefs = c(5,.2,-1.5,.9)
mu = X %*% coefs
sigma = 2
y <- rnorm(N, mu, sigma)
# same as
# y = 5 + .2*X1 - 1.5*X2 + .9*X3 + rnorm(N, mean=0, sd=2)
# Run lm for later comparison; but go ahead and examine now if desired
modlm = lm(y~., data=data.frame(X[,-1]))
# summary(modlm)
# Chunk 9: data4Stan
# Create the data list object for stan inupt
dat = list(N=N, K=ncol(X), y=y, X=X)
# Chunk 10: stanModel
# Create the stan model object using Stan's syntax
stanmodelcode = "
data { // Data block
int<lower=1> N; // Sample size
int<lower=1> K; // Dimension of model matrix
matrix[N, K] X; // Model Matrix
vector[N] y; // Target variable
}
/*
transformed data { // Transformed data block. Not used presently.
}
*/
parameters { // Parameters block
vector[K] beta; // Coefficient vector
real<lower=0> sigma; // Error scale
}
model { // Model block
vector[N] mu;
mu <- X * beta; // Creation of linear predictor
// priors
beta ~ normal(0, 10);
sigma ~ cauchy(0, 5); // With sigma bounded at 0, this is half-cauchy
// likelihood
y ~ normal(mu, sigma);
}
/*
generated quantities { // Generated quantities block. Not used presently.
}
*/
"
# Chunk 11: runModel
library(rstan)
### Run the model and examine results ###
fit = stan(model_code=stanmodelcode, data=dat, iter=12000,
warmup=2000, thin=10, chains=3)
print(fit, digits_summary=3, pars=c('beta','sigma'),
probs = c(.025, .5, .975))
summary(modlm)
traceplot(fit, pars=c('beta[4]'), cex.main=.75, cex.axis=.5, cex.lab=.5)
library(ggplot2)
traceplot(fit, pars=c('beta[4]'), cex.main=.75, cex.axis=.5, cex.lab=.5)
?traceplot
plotTrace(fit, pars=c('beta[4]'), cex.main=.75, cex.axis=.5, cex.lab=.5)
traceplot(fit, pars=c('beta[4]'))
traceplot(fit, pars=c('beta[4]', cex.main=.75, cex.axis=.5, cex.lab=.5))
traceplot(fit, pars=c('beta[4]'), par(cex.main=.75, cex.axis=.5, cex.lab=.5))
par(cex.main=.75, cex.axis=.5, cex.lab=.5)
traceplot(fit, pars=c('beta[4]'))
par(cex.main=.75, cex.axis=.5, cex.lab=.5, mfrow=c(2,2))
for (i in 1:4)
traceplot(fit, pars=c('beta[i]'))
beta
beta[2]
for (i in 1:3)
traceplot(fit, pars=c('beta[i]'))
traceplot(fit, pars=c('beta[3]'))
paste0('beta[',i,']')
par(cex.main=.75, cex.axis=.5, cex.lab=.5, mfrow=c(2,2))
for (i in 1:4)
traceplot(fit, pars=c(paste0('beta[',i,']'))
)
par(cex.main=.75, cex.axis=.5, cex.lab=.5, mfrow=c(2,2))
for (i in 1:4)
traceplot(fit, pars=c(paste0('beta[',i,']')))
# following parameters seem to fail: cex.main=.75, cex.axis=.5, cex.lab=.5
traceplot(fit, pars=c(paste0('beta[',i,']')))
par(cex.main=.75, cex.axis=.5, cex.lab=.5, mfrow=c(2,2))
traceplot(fit, pars=c(paste0('beta[',i,']')))
for (i in 1:4)
traceplot(fit, pars=c(paste0('beta[',i,']')))
for (i in 1:4) print(i)
for (i in 1:1)
traceplot(fit, pars=c(paste0('beta[',i,']')))
traceplot(fit, pars=c(paste0('beta[',i,']')))
for (i in 1:1){
traceplot(fit, pars=c(paste0('beta[',i,']')))
}
par(cex.main=.75, cex.axis=.5, cex.lab=.5, mfrow=c(2,2))
for (i in 1:4){
traceplot(fit, pars=c(paste0('beta[',i,']')))
}
for (i in 1:4){
Sys.sleep(0)
traceplot(fit, pars=c(paste0('beta[',i,']')))
}
16813-14340
18418-16813
q()
survData <- data.frame( id=c(1,2,3))
survData
survData <- data.frame(id=c(1,2,2,3,3,3), event=c(1,0,1,0,0,1))
survData
survData <- data.frame(id=c(1,2,2,3,3,3), event=c(1,0,1,0,0,1), start=c(0, 0, 150, 0, 150, 300))
survData
survData <- data.frame(id=c(1,2,2,3,3,3), event=c(1,0,1,0,0,1), start=c(0, 0, 150, 0, 150, 300), stop=c(150, 150, 300, 150, 300, 600))
survData
survData <- data.frame(id=c(1,2,2,3,3,3), event=c(1,0,1,0,0,1), start=c(0, 0, 150, 0, 150, 300), stop=c(150, 150, 300, 150, 300, 600), tnCmin=c(10, 10, 10, 10, 10, 10))
survData
Conc <- matrix(c(12, 10, 5, 6, 4, 2, 3, 1, .5), byrow=F, nrow=3)
beta<- 1
Lplus <- (exp(beta*Conc[1,1])/(exp(beta*Conc[1,1]) + exp(beta*Conc[2,1]) + exp(beta*Conc[3,1])))*
(exp(beta*Conc[2,2])/(exp(beta*Conc[2,2]) + exp(beta*Conc[3,2])))
Lplus
beta <- -1
Lminus <- (exp(beta*Conc[1,1])/(exp(beta*Conc[1,1]) + exp(beta*Conc[2,1]) + exp(beta*Conc[3,1])))*
(exp(beta*Conc[2,2])/(exp(beta*Conc[2,2]) + exp(beta*Conc[3,2])))
Lminus
exp(5)/(exp(5) + exp(10) + exp(12))
(exp(5)/(exp(5) + exp(10) + exp(12)))*(exp(4)/(exp(4)+exp(6)))
(exp(-5)/(exp(-5) + exp(-10) + exp(-12)))*(exp(-4)/(exp(-4)+exp(-6)))
exp(-1)
library("survival")
model.2 <- coxph(Surv(start, stop, event) ~ tnCmin, data = survData)
survData <- data.frame(id=c(1,2,2,3,3,3), event=c(1,0,1,0,0,1),
start=c(0, 0, 150, 0, 150, 300), stop=c(150, 150, 300, 150, 300, 600),
tnCmin=c(3.333, 1.333, 2.667, 0.833, 1.667, 3.333))
survData
library("survival")
model.2 <- coxph(Surv(start, stop, event) ~ tnCmin, data = survData)
model.1 <- coxph(Surv(start, stop, event) ~ tnCmin, data = survData)
summary(survfit(model.1, type = "aalen"))
model.1
exp(1.98)
?coxph
survData <- data.frame(id=c(1,2,2,3,3,3), event=c(1,0,1,0,0,1),
start=c(0, 0, 150, 0, 150, 300), stop=c(150, 150, 300, 150, 300, 600),
tnCmin=c(3.333, 1.333, 2.667, 0.833, 1.667, 3.333))
survData
survData <- data.frame(id=c(1,2,2,3,3,3), event=c(1,0,1,0,0,1),
start=c(0, 0, 150, 0, 150, 300), stop=c(150, 150, 300, 150, 300, 600),
tnCmin=c(3.333, 5.333, 2.667, 6.667, 3.333,  0.833))
survData
model.1 <- coxph(Surv(start, stop, event) ~ tnCmin, data = survData)
summary(survfit(model.1, type = "aalen"))
survData
id4 <- data.frame(id=c(4,4,4,4), event=c(0,0,0,1),
start=c(0, 150, 300, 600), stop=c(150, 300, 600, 700),
tnCmin=c(5.667, 2.333, 0.667, 0.333))
id4
survDataMore <- rbind(survData, id4)
survDataMore
survData4 <- rbind(survData, id4)
model.4 <- coxph(Surv(start, stop, event) ~ tnCmin, data = survData4)
summary(survfit(model.4, type = "aalen"))
library("survival")
model.1 <- coxph(Surv(start, stop, event) ~ tnCmin, data = survData)
summary(survfit(model.1, type = "aalen"))
model.4 <- coxph(Surv(start, stop, event) ~ tnCmin, data = survData4)
model.4
summary(survfit(model.4, type = "aalen"))
model.4
model.1 <- coxph(Surv(start, stop, event) ~ tnCmin, data = survData)
exp(-800)
exp(800)
840+714+1380+680+982+624+320
q()
q()
3/5
4/6
round(0.5)
round(1.5)
round(3.5)
round(2.5)
q()
q()
1375+1075
1775+1075
q()
library(slidify)
install.packages(slidify)
install.packages("devtools")
library(devtools)
install_github('slidify', 'ramnathv')
install_github('slidifyLibraries', 'ramnathv')
install_github('ramnathv/slidifyLibraries', 'ramnathv')
library(slidify)
q()
19.80+38+133
q()
q()
slidify("index.Rmd")
library(slidify)
slidify("index.Rmd")
setwd("~/juicy/BioStatWork2012/mytex/journalClub/pvaluesCI")
slidify("index.Rmd")
setwd("~/juicy/BioStatWork2012/mytex/journalClub/pvaluesCI/pvalsCIslide")
slidify("index.Rmd")
setwd("~/juicy/BioStatWork2012/mytex/journalClub/Reproducibility/repBioInfo")
slidify("index.Rmd")
library(wordcloud)
PKwords <- c("PK", "PD", "AUC", "Cmin", "Cmax", "Tmax", "TTE", "Cox", "Cox PH", "Pharmacokinetics", "Pharmacodynamics", "ER")
nW <- length(PKwords) # sample(1:nW, nW)
pkFreq <- c(5,5,1,2,2,2,3,3,3,1,1,1)
# pdf("sampleCloud.pdf", width=6, height=4)
wordcloud(PKwords, pkFreq,  colors=brewer.pal(8, "Dark2"), min.freq=1,random.color=TRUE)
install.package(wordcloud)
install.packages(wordcloud)
install.packages("wordcloud")
library(wordcloud)
PKwords <- c("PK", "PD", "AUC", "Cmin", "Cmax", "Tmax", "TTE", "Cox", "Cox PH", "Pharmacokinetics", "Pharmacodynamics", "ER")
nW <- length(PKwords) # sample(1:nW, nW)
pkFreq <- c(5,5,1,2,2,2,3,3,3,1,1,1)
# pdf("sampleCloud.pdf", width=6, height=4)
wordcloud(PKwords, pkFreq,  colors=brewer.pal(8, "Dark2"), min.freq=1,random.color=TRUE)
install.packages("RColorBrewer")
install.packages("RColorBrewer")
install.packages("wordcloud")
library(wordcloud)
PKwords <- c("PK", "PD", "AUC", "Cmin", "Cmax", "Tmax", "TTE", "Cox", "Cox PH", "Pharmacokinetics", "Pharmacodynamics", "ER")
nW <- length(PKwords) # sample(1:nW, nW)
pkFreq <- c(5,5,1,2,2,2,3,3,3,1,1,1)
# pdf("sampleCloud.pdf", width=6, height=4)
wordcloud(PKwords, pkFreq,  colors=brewer.pal(8, "Dark2"), min.freq=1,random.color=TRUE)
install.packages("slam")
library(slam)
install.packages("slam")
q()
